import torch
import torch.nn as nn
import numpy as np
from torchvision import models, transforms, datasets
from tqdm import tqdm
import os
import sys
import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt
from matplotlib.patches import Ellipse
from torch.utils.data import TensorDataset, DataLoader
import shutil
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
import json
import math
'''
ä¼ å‚æ€è·¯:

    main[ä¸»å‡½æ•°] -->|åˆå§‹åŒ–| universal_perturbation[å…¨å±€æ‰°åŠ¨]
    main -->|é€ç±»åˆ«å¾ªç¯| attack[æ”»å‡»å®ä¾‹]
    attack -->|ä¼ å…¥| universal_perturbation
    attack -->|æ›´æ–°| universal_perturbation
    evaluate_global_accuracy -->|åº”ç”¨æ‰°åŠ¨| universal_perturbation
'''
# --- å…¨å±€è¶…å‚æ•° ---
epsilon = 0.14       # æ€»æ‰°åŠ¨é¢„ç®—
block_size = 16     # å—å°ºå¯¸
num_samples = 5     # æ¯è½®é‡‡æ ·å—æ•°
max_iter = 50      # å¢åŠ è¿­ä»£æ¬¡æ•°ä»¥è§‚å¯Ÿè¶‹åŠ¿,è¿™ä¸ªä¸åº”è¯¥è®¾çš„å¤ªå°(æ¯”å¦‚3)
mu = 3              # æˆåŠŸæ ·æœ¬ä¿ç•™æ•°
num_test_classes = 20  # æµ‹è¯•ç±»åˆ«æ•°ï¼ˆä»200ç±»ä¸­éšæœºé€‰æ‹©ï¼‰
target_class = None # å½“å‰æ˜¯æ— ç›®æ ‡æ”»å‡» 
lambda_sparsity = 0.3  # ç¨€ç–æ€§æ­£åˆ™åŒ–ç³»æ•°

debug_mode = 1  # 1å¯ç”¨æ—¥å¿—å’ŒæŠ¥å‘Šï¼Œ0ç¦ç”¨ï¼ˆè®¾ç½®ä¸º0æ—¶æ‰§è¡ŒåŸç‰ˆé€»è¾‘ï¼‰

# --- CMA-ES å‚æ•° ---
cma_lambda = 10     # ç§ç¾¤å¤§å°
cma_mu = 5          # çˆ¶ä»£æ•°é‡
cma_sigma = 0.5     # åˆå§‹æ­¥é•¿
img_size = 64 #tiny-imagenetçš„å¤§å°æ˜¯64


train_transform = transforms.Compose([
    transforms.RandomResizedCrop(img_size),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ToTensor(),
    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2770, 0.2691, 0.2821])
])

val_transform = transforms.Compose([
    transforms.Resize(img_size),
    transforms.CenterCrop(img_size),
    transforms.ToTensor(),
    transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2770, 0.2691, 0.2821])
]) #è¿™é‡Œå·²ç»è¿›è¡Œå½’ä¸€åŒ–äº†ï¼Œåªèƒ½æœ‰è¿™ä¸€æ¬¡ï¼Œåé¢éƒ½ä¸è®¸å½’ä¸€åŒ–ï¼
# åœ¨ evaluate å’Œ attack ç­‰å‡½æ•°ä¸­ä¸éœ€è¦å†æ¬¡è°ƒç”¨ normalize



# éšæœºæ€§çš„é™å®š--ä½¿å¾—æ¨¡å‹å‡†ç¡®ç‡åœ¨æ¯æ¬¡è¿è¡Œçš„è¿‡ç¨‹ä¸­æ›´ç¨³å®š,ä¾¿äºåˆ†æ
def set_seed(seed=42):
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ç¡®ä¿å·ç§¯æ“ä½œç¡®å®šæ€§
    torch.backends.cudnn.benchmark = False     # å…³é—­è‡ªåŠ¨ä¼˜åŒ–(é¿å…å¼•å…¥éšæœºæ€§)

# ---------------------------- æ•°æ®åŠ è½½ ---------------------------
def get_tinyimagenet_loader(data_dir, batch_size=64, train=False):
    """åŠ è½½Tiny ImageNetæ•°æ®é›†"""
    transform = val_transform if not train else train_transform  # æ ¹æ®æ˜¯å¦æ˜¯è®­ç»ƒé›†é€‰æ‹©ä¸åŒçš„é¢„å¤„ç†
    # è¿™é‡Œçš„val_transformæ˜¯å·²ç»è¿›è¡Œå½’ä¸€åŒ–çš„
    
    dataset_path = os.path.join(data_dir, 'train' if train else 'val')
    
    # æ¸…ç†æ£€æŸ¥ç‚¹æ–‡ä»¶å¤¹
    checkpoint_path = os.path.join(dataset_path, '.ipynb_checkpoints')
    if os.path.exists(checkpoint_path):
        shutil.rmtree(checkpoint_path)
    
    dataset = datasets.ImageFolder(dataset_path, transform=transform)
    return DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

class DebugVGG16(nn.Module):
    """åŠ è½½æœ¬åœ°é¢„è®­ç»ƒçš„VGG16æ¨¡å‹"""
    def __init__(self, num_classes=200):
        super().__init__()
        # åˆå§‹åŒ–æ ‡å‡†VGG16ç»“æ„ï¼ˆä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
        # æˆ‘å°è¯•è¿‡,è¿™é‡ŒåŠ è½½weights=models.VGG16_Weights.IMAGENET1K_V1ä¸ä¼šæœ‰æ€§èƒ½æå‡,å’ŒNoneæ˜¯ä¸€æ ·çš„
        original_model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1) 
        
        # ç‰¹å¾æå–å±‚ä¿æŒä¸å˜
        self.features = original_model.features
        
        # åŠ¨æ€è®¡ç®—åˆ†ç±»å™¨è¾“å…¥ç»´åº¦ï¼ˆé€‚é…64x64è¾“å…¥ï¼‰
        with torch.no_grad():
            dummy = torch.randn(1, 3, 64, 64)
            features = self.features(dummy)
            # in_features = features.view(1, -1).size(1) # è¿™è¡Œå’Œä¸‹é¢é‚£è¡Œåªèƒ½ç•™ä¸‹ä¸€è¡Œ
            in_features = features.view(-1).shape[0] # è¿™è¡Œæ˜¯ç›´æ¥ä»train.pyä¸­æŠ„è¿‡æ¥çš„

        # é‡å»ºåˆ†ç±»å™¨å±‚
        self.classifier = nn.Sequential(
            nn.Linear(in_features, 4096),
            nn.ReLU(True),
            nn.Dropout(0.5), #è¿™ä¸ªæ”¾åœ¨åˆ«å¤„å¯èƒ½ä¹Ÿä¼šå½±å“æ€§èƒ½ï¼Œä½†æ˜¯è¿™é‡Œå’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ã€‚æˆ‘è§‰å¾—å¯èƒ½å½±å“ä¸å¤§
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(0.5), #åŒä¸Š
            nn.Linear(4096, num_classes)
        )

        # åŠ è½½æœ¬åœ°é¢„è®­ç»ƒæƒé‡
        pretrained_dict = torch.load("./train_vgg16/best_vgg16.pth", map_location="cuda:0")
        self.load_state_dict(pretrained_dict)
        # åŠ è½½æƒé‡åï¼Œæ‰“å°ç¼ºå¤±å’Œæ„å¤–çš„é”®
        missing, unexpected = self.load_state_dict(pretrained_dict, strict=False)
        print("ç¼ºå¤±çš„é”®ï¼ˆæœªåŠ è½½çš„æƒé‡ï¼‰:", missing)
        print("æ„å¤–çš„é”®ï¼ˆå¤šä½™çš„æƒé‡ï¼‰:", unexpected)
        print("æˆåŠŸåŠ è½½æœ¬åœ°VGG16æƒé‡")



    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x
# ---------------------------- CMA-ESä¼˜åŒ–å™¨ ---------------------------
class CMAESBlock:
    """ç®¡ç†æ¯ä¸ªå—çš„CMA-ESä¼˜åŒ–å™¨"""
    def __init__(self, block_size):
        self.dim = block_size**2 * 3  # è¿™ä¸ªå¥½åƒæ˜¯å—ä¸­çš„åƒç´ ç‚¹ä¸ªæ•°ï¼Œä¸€ä¼šæ‰“å°ä¸€ä¸‹ï¼Ÿ
        # åŠ¨æ€è®¡ç®— lambda å’Œ mu
        self.lambda_ = int(4 + 3 * math.log(self.dim))  # å…¬å¼ Î» = 4 + 3*ln(n)
        self.mu = max(1, self.lambda_ // 2)             # Î¼ = Î»/2ï¼ˆå‘ä¸‹å–æ•´ï¼Œè‡³å°‘ä¸º1ï¼‰
        
        self.mean = np.zeros(self.dim)
        self.C = np.eye(self.dim)  # åæ–¹å·®çŸ©é˜µ;åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µ
        self.sigma = cma_sigma
        self.p_sigma = np.zeros(self.dim)
        self.p_c = np.zeros(self.dim)
        self.mu = cma_mu
        self.lambda_ = cma_lambda
        self.cc = 4 / (self.dim + 4)
        self.c1 = 2 / ((self.dim + 1.3)**2 + self.mu)
        self.cmu = 2 * (self.mu - 2 + 1/self.mu) / ((self.dim + 2)**2 + self.mu)
        self.damps = 1 + 2*max(0, np.sqrt((self.mu-1)/(self.dim+1))-1) + self.cc
        self.chi_n = np.sqrt(self.dim) * (1 - 1/(4*self.dim) + 1/(21*self.dim**2))


        # æ–°å¢æƒé‡å®šä¹‰
        self.weights = np.array([np.log(self.mu + 0.5) - np.log(i+1) for i in range(self.mu)])
        self.weights = self.weights / self.weights.sum()

        # å†å²è®°å½•ï¼Œåé¢ç”»CMA-ESå›¾æœ‰ç”¨
        self.sigma_history = []     # è®°å½•sigmaçš„æ¼”åŒ–

        #è¿™æ˜¯ä¸ºäº†å—å†…ç¨€ç–(è¿›è€Œä½“ç°ä¸ºæ•´ä½“ç¨€ç–)è€Œå¼•å…¥çš„
        # æ–°å¢ç¨€ç–æ€§å‚æ•°
        self.sparsity = 0.1             # åˆå§‹ç¨€ç–åº¦ï¼ˆæ‰°åŠ¨å‰10%çš„åƒç´ ï¼‰
        self.active_pixels = []         # è®°å½•å½“å‰æ¿€æ´»çš„åƒç´ ç´¢å¼•



    def sample(self):
        """ç”Ÿæˆå€™é€‰æ ·æœ¬"""
        return [self.sigma * np.random.multivariate_normal(self.mean, self.C) 
                for _ in range(self.lambda_)]

    def update(self, parents):
        """æ›´æ–°å‚æ•°"""
        
        if len(parents) != self.mu:
            raise ValueError("Parentsæ•°é‡å¿…é¡»ç­‰äºmu")

        # å…ˆå‰çš„æ›´æ–°å‡å€¼ç­–ç•¥ï¼Œç°å·²æ›¿æ¢æˆåŠ æƒ
        # new_mean = np.mean(parents, axis=0) 

        # åŠ æƒå‡å€¼è®¡ç®—
        weighted_mean = np.zeros_like(self.mean)
        for w, x in zip(self.weights, parents):
            weighted_mean += w * x
        new_mean = weighted_mean




        y = (new_mean - self.mean) / self.sigma # --è¿™ä¸ªæ˜¯è¿›åŒ–è·¯å¾„è®¡ç®—ä¸­çš„ä¸€é¡¹
        self.p_sigma = (1 - self.cc) * self.p_sigma + np.sqrt(self.cc*(2-self.cc)*self.mu) * y #æ›´æ–°è¿›åŒ–è·¯å¾„(æ­¥é•¿)
        sigma_norm = np.linalg.norm(self.p_sigma) / self.chi_n
        self.sigma *= np.exp((sigma_norm - 1) * self.cc / self.damps) # æ›´æ–°æ­¥é•¿
        # self.p_c = (1 - self.cc) * self.p_c + np.sqrt(self.cc*(2-self.cc)*self.mu) * y # æ›´æ–°è¿›åŒ–è·¯å¾„(åæ–¹å·®çŸ©é˜µ)
        # delta_C = np.outer(self.p_c, self.p_c) * self.c1 #--è¿™ä¸ªæ˜¯æ›´æ–°åæ–¹å·®çŸ©é˜µçš„ç¬¬äºŒé¡¹
        for x in parents:
            z = (x - self.mean) / self.sigma
            # delta_C += self.cmu * np.outer(z, z)
        # self.C = (1 - selff.c1 - self.cmu) * self.C + delta_C
        self.mean = new_mean.copy()
        # self.C = (self.C + self.C.T) / 2
        # æ‰“å°æ›´æ–°åçš„å‚æ•°
        # print(f"å‡å€¼å˜åŒ–èŒƒæ•°: {np.linalg.norm(self.mean - old_mean):.4f}")
        # print(f"åæ–¹å·®çŸ©é˜µè¿¹: {np.trace(self.C):.4f}")

        # è®°å½•å†å²çŠ¶æ€,åé¢ç”»CMA-ESå›¾æœ‰ç”¨
        self.sigma_history.append(self.sigma)


class EarlyStopping:
    def __init__(self, patience=5, min_delta=0.0001):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, val_acc):
        score = val_acc
        if self.best_score is None:
            self.best_score = score
            # print(f"Initial best score: {self.best_score}")
        elif score > self.best_score - self.min_delta:# å‡†ç¡®ç‡è¶Šä½è¶Šå¥½
            self.counter += 1
            # print(f"Score {score} is less than best score {self.best_score} + min_delta {self.min_delta}. Counter: {self.counter}")
            if self.counter >= self.patience:
                self.early_stop = True
                print(f"Early stopping triggered at score {score} after {self.counter} iterations without improvement.")
        else:
            self.best_score = score
            self.counter = 0
            # print(f"New best score: {self.best_score}")
        return self.early_stop
# ---------------------------- æ”»å‡»ç±» ---------------------------
class SZOAttack:
    """ç¨€ç–åŒºåŸŸä¼˜åŒ–çš„å¯¹æŠ—æ”»å‡»"""
    def __init__(self, model, image, label, block_size, device, epsilon=0.1,universal_perturbation = None,original_path=None):  # æ–°å¢epsilonå‚æ•°
        self.device = image.device  # ç»§æ‰¿è¾“å…¥å›¾åƒçš„è®¾å¤‡
        self.model = model.to(self.device)
        self.original_image = image.clone().detach().to(self.device) #ç”±äºåœ¨transformå‡½æ•°ä¸­å·²ç»åšè¿‡å½’ä¸€åŒ–ï¼Œè¿™é‡Œä¹Ÿæ˜¯å½’ä¸€åŒ–è¿‡çš„
        self.label = label.to(self.device) if isinstance(label, torch.Tensor) else torch.tensor(label, device=self.device)
        #20250308 è¿™ä¸€ç‰ˆä¸çŸ¥é“æ€ä¹ˆäº†ï¼Œä¹‹å‰åæ–¹å·®çŸ©é˜µä¹Ÿèƒ½æ›´æ–°ä¸”ä¸ç”¨è¾“å‡ºæ”»å‡»æŠ¥å‘Šçš„æ—¶å€™ï¼Œlabelä¹Ÿä¸æ˜¯å¼ é‡(æˆ‘è®°å¾—æ˜¯int)ï¼Œä¹Ÿå¯ä»¥to.device(),
        #ä½†æ˜¯ç°åœ¨ä¸è¡Œäº†ï¼Œæ‰€ä»¥åªèƒ½å¼„æˆtensor.åç»­åˆå‡ºç°self.universal_perturbation å’Œ delta ä¸åœ¨åŒä¸€ä¸ªè®¾å¤‡ä¸Šï¼Œdeltaä¹Ÿè¦to.device().

        self.block_size = block_size
        self.epsilon = epsilon  # å…³é”®ï¼šå®šä¹‰epsilonå±æ€§
        self.original_path = original_path  # å­˜å‚¨åŸå§‹å›¾åƒè·¯å¾„
        
        # ç¡®ä¿æ‰€æœ‰åˆå§‹åŒ–å¼ é‡åœ¨GPU
        self.H, self.W = image.shape[-2:]  # ä½¿ç”¨æœ€åä¸¤ä¸ªç»´åº¦ï¼ˆH,Wï¼‰
        self.num_blocks_h = (self.H + block_size - 1) // block_size
        self.num_blocks_w = (self.W + block_size - 1) // block_size
        self.total_blocks = self.num_blocks_h * self.num_blocks_w
        
        # ä½¿ç”¨GPUå¼ é‡åˆå§‹åŒ–æ¦‚ç‡
        self.prob = torch.ones(self.total_blocks, device=self.device) / self.total_blocks
        
        # é¢„åˆ†é…GPUæ˜¾å­˜ç©ºé—´
        self.best_adv = torch.empty_like(self.original_image, device=self.device)
        self.best_loss = -np.inf
        self.target_class = None
        
        # å…¶ä»–åˆå§‹åŒ–ä»£ç ...
        self.global_acc_history = []  # æ–°å¢ï¼šåˆå§‹åŒ–å†å²è®°å½•åˆ—è¡¨
        self.eval_interval = 1        # æ¯æ¬¡è¿­ä»£è¯„ä¼°ä¸€æ¬¡å…¨å±€å‡†ç¡®ç‡

        # è¿™ä¸ªå®šä¹‰ä¹‹å‰æ²¡å†™ä¹Ÿå¯ä»¥è¿è¡Œï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼Œè¿˜æ˜¯å…ˆè¡¥ä¸Šäº†
        self.cma_blocks = {bid: CMAESBlock(block_size) for bid in range(self.total_blocks)}


        # for bid in range(self.total_blocks):
        #     block_pixels = block_size**2 * 3  # è®¡ç®—å—åƒç´ æ•° (RGB)
        #     self.cma_blocks[bid] = CMAESBlock(block_pixels)
        #     print(f"å— {bid}: åƒç´ æ•°={block_pixels}, lambda={self.cma_blocks[bid].lambda_}, mu={self.cma_blocks[bid].mu}")
        # åˆå§‹åŒ–æ—¶,æ¥æ”¶å¤–éƒ¨ä¼ å…¥çš„å…¨å±€æ‰°åŠ¨
        if universal_perturbation is None:
            self.universal_perturbation = torch.zeros_like(image.unsqueeze(0), device=device)
        else:
            self.universal_perturbation = universal_perturbation.clone().to(self.device)
        ##ä¸Šé¢è¿™è¡Œä»£ç çš„åŸå› : [1,3,H,W],è®¾ç½®ä¸º4ç»´,è¿™æ ·æ‰èƒ½ä¸imageåŒ¹é…(images.shape = [64, 3, 64, 64]  # Batch size=64)
        self.early_stopping = EarlyStopping(patience=10, min_delta=0.0001)  # åˆå§‹åŒ–æ—©åœç­–ç•¥

        # æ¡ä»¶åŒ–åˆå§‹åŒ–å¯è§†åŒ–ç»„ä»¶
        if debug_mode:
            self.visualizer = AttackVisualizer(
                H=self.H,  # æ­£ç¡®ä¼ é€’å‚æ•°
                W=self.W,
                block_size=self.block_size,
                device=self.device
            )
            # self.logger = CMAESLogger(
            #     total_blocks=self.total_blocks,  # å‚æ•°åä¿®æ­£log_block_selection
            #     device=self.device
            # )
        else:
            self.visualizer = None
            # self.logger = None


    # def _log_iteration(self, class_id, iteration, selected_blocks, delta):
    #     """è®°å½•å•æ¬¡è¿­ä»£çš„æ‰€æœ‰ä¿¡æ¯:åŒ…å«å¯¹self.visualizer.log_block_selectionå’Œself.visualizer.plot_perturbationçš„è°ƒç”¨"""
    #     if not debug_mode:
    #         return
    #     # å—é€‰æ‹©æ—¥å¿—
    #     self.visualizer.log_block_selection(
    #         class_id=class_id,
    #         iteration=iteration,
    #         selected_blocks=selected_blocks,
    #         prob_dist=self.prob.cpu()
    #     )
        
    #     # CMA-ESçŠ¶æ€è®°å½•
    #     for bid in selected_blocks:
    #         cma_state = {
    #             'mean': self.cma_blocks[bid].mean,
    #             'C': self.cma_blocks[bid].C,
    #             'sigma': self.cma_blocks[bid].sigma,
    #             'fitness': self.cma_blocks[bid].best_fitness
    #         }
            
    #     # æ‰°åŠ¨å¯è§†åŒ–
    #     self.visualizer.plot_perturbation(
    #         delta=delta.detach().cpu(),
    #         universal_pert=self.universal_perturbation.detach().cpu(),
    #         iteration=iteration
    #     )
    
    def block_projection(self, delta, bid): #return delta
        """å…¨GPUåŒ–çš„å—æŠ•å½±"""
        num_blocks_per_row = (self.W + self.block_size - 1) // self.block_size
        h_start = (bid // num_blocks_per_row) * self.block_size
        w_start = (bid % num_blocks_per_row) * self.block_size
        
        # ä½¿ç”¨GPUåŠ é€Ÿçš„åˆ‡ç‰‡æ“ä½œ
        h_slice = slice(max(0, h_start), min(h_start+self.block_size, self.H))
        w_slice = slice(max(0, w_start), min(w_start+self.block_size, self.W))

        h_pixels = h_slice.stop - h_slice.start
        w_pixels = w_slice.stop - w_slice.start
        # print(f"h_pixels: ", h_pixels) #æ‰“å°å‡ºæ¥æ˜¯block_size
        # print(f"w_pixels: ", w_pixels) #æ‰“å°å‡ºæ¥ä¹Ÿæ˜¯block_size

        # è·å–å½“å‰å—çš„CMAå‚æ•°
        cma_block = self.cma_blocks[bid]
        
        # ç”Ÿæˆå…¨æ‰°åŠ¨å‘é‡ï¼ˆæœªç¨€ç–åŒ–ï¼‰
        full_perturbation = cma_block.sigma * np.random.multivariate_normal(
            cma_block.mean, cma_block.C
        )
        
        # (ç¡¬ç¨€ç–)ç¨€ç–åŒ–ï¼šé€‰æ‹©å½±å“åŠ›æœ€å¤§çš„å‰kä¸ªåƒç´ 
        # perturbation_flat = full_perturbation.reshape(-1)
        k = int(cma_block.sparsity * len(full_perturbation))  # æ‰°åŠ¨åƒç´ æ•°é‡
        top_indices = np.argsort(np.abs(full_perturbation))[-k:]  # é€‰æ‹©ç»å¯¹å€¼æœ€å¤§çš„kä¸ª
        
        # ç”Ÿæˆç¨€ç–æ‰°åŠ¨çŸ©é˜µ
        sparse_perturbation = np.zeros(3 * h_pixels * w_pixels)  
        sparse_perturbation[top_indices] = full_perturbation[top_indices]
        sparse_perturbation = sparse_perturbation.reshape(3, h_pixels, w_pixels)
        
        # åº”ç”¨æ‰°åŠ¨åˆ°delta
        delta[:, h_slice, w_slice] += torch.tensor(sparse_perturbation, 
                                                device=self.device)
        return delta

    def sample_perturbations(self): # return delta.to(self.device), selected_blocks
        """æ‰¹é‡ç”ŸæˆGPUæ‰°åŠ¨"""
        selected_blocks = torch.multinomial(self.prob, num_samples, replacement=True)
        valid_bids = selected_blocks.unique().cpu().numpy()  # ä»…CPUç”¨äºç´¢å¼•è®¡ç®—
        
        # é¢„åˆ†é…GPUæ˜¾å­˜
        delta = torch.zeros_like(self.original_image, device=self.device)
        
        # å¹¶è¡ŒåŒ–å—å¤„ç†
        for bid in valid_bids:
            if bid >= self.total_blocks:
                continue
            delta = self.block_projection(delta, bid)
        
        return delta.to(self.device), selected_blocks
    
    
    def evaluate(self, adv_images): # return losses
        """è¯„ä¼°å¯¹æŠ—æ ·æœ¬"""
        with torch.no_grad():
            logits = self.model(adv_images)
            
            if self.target_class is None:
                # éç›®æ ‡æ”»å‡»ï¼šæœ€å¤§åŒ–åŸå§‹ç±»åˆ«æŸå¤±
                target = torch.full((logits.size(0),), self.label, device=self.device)
                losses = nn.CrossEntropyLoss(reduction='none')(logits, target)
            else:
                 # ç›®æ ‡æ”»å‡»ï¼šæœ€å°åŒ–ç›®æ ‡ç±»åˆ«æŸå¤±
                target = torch.full((logits.size(0),), self.target_class, device=self.device)
                losses = -nn.CrossEntropyLoss(reduction='none')(logits, target)
            # æ·»åŠ æ­£åˆ™åŒ–é¡¹ï¼ˆç¡®ä¿ç³»æ•°åˆç†ï¼‰
            sparsity_penalty = torch.norm(adv_images - self.original_image, p=1)
            losses += lambda_sparsity * sparsity_penalty
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            # print(f"å¹³å‡æŸå¤±: {losses.mean().item():.4f}, æ­£åˆ™åŒ–é¡¹: {sparsity_penalty.item():.4f}")
            return losses

    def update_prob(self, blocks, losses):
        """æ›´æ–°é€‰æ‹©æ¦‚ç‡"""
        success_blocks = blocks[losses.argsort(descending=True)[:mu]]
        self.prob = torch.zeros_like(self.prob)
        unique_blocks, counts = torch.unique(success_blocks, return_counts=True)
        # æ‰“å°å‡ºæ¯æ¬¡æ›´æ–°çš„æ¦‚ç‡ä¿¡æ¯
        print(f"\nUpdating probability with success blocks: {success_blocks[:10]}")  # æ‰“å°å‰10ä¸ªæˆåŠŸçš„å—
        for b, cnt in zip(unique_blocks, counts):
            self.prob[b] = cnt.float()**1
        self.prob = (self.prob + 0.01) / (self.prob.sum() + 0.01 * self.prob.size(0))
        print(f"\nUpdated probabilities: {self.prob[:10]}")  # æ‰“å°å‰10ä¸ªæ¦‚ç‡
        # æ›´æ–°CMAå‚æ•°
        for bid in unique_blocks.cpu().numpy():
            parents = [self.cma_blocks[bid].mean + self.cma_blocks[bid].sigma * 
                      np.random.multivariate_normal(np.zeros(self.cma_blocks[bid].dim), self.cma_blocks[bid].C)
                      for _ in range(self.cma_blocks[bid].mu)]
            self.cma_blocks[bid].update(parents)

        # 1.3.1ç‰ˆæœ¬æ–°å¢ï¼šåŠ¨æ€è°ƒæ•´æ¯ä¸ªå—çš„ç¨€ç–åº¦
        for bid in unique_blocks.cpu().numpy():
            block = self.cma_blocks[bid]
            if block.sparsity > 0.05:  # æœ€ä½ç¨€ç–åº¦5%
                # å¦‚æœå—è¡¨ç°å¥½ï¼Œé™ä½ç¨€ç–åº¦ï¼ˆå…è®¸æ›´å¤šåƒç´ è¢«æ‰°åŠ¨ï¼‰
                block.sparsity *= 0.95 if losses.mean() < self.best_loss else 1.1



    def attack_batch(self, images, labels):
        """å…¨GPUæ‰¹é‡æ”»å‡»"""
        # ç¡®ä¿è¾“å…¥æ•°æ®åœ¨GPU
        images = images.to(self.device)
        labels = labels.to(self.device)
        
        # é¢„åˆ†é…ç»“æœæ˜¾å­˜
        adv_images = torch.empty_like(images, device=self.device)
        
        # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ›¿ä»£å¤šçº¿ç¨‹
        for i in range(images.shape[0]):
            # attacker = SZOAttack(self.model, images[i], labels[i], self.block_size,device=self.device,epsilon=self.epsilon) # ä¼ é€’å…¨å±€å‚æ•°)
            # åº”ç”¨å½“å‰çš„å…¨å±€æ‰°åŠ¨
            # perturbed_img = torch.clamp(images[i] + self.universal_perturbation, 0, 1)
            perturbed_img = images[i] + self.universal_perturbation

            adv_images[i] = perturbed_img.squeeze(0)  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            
            # æ˜¾å­˜ä¼˜åŒ–
            if i % 10 == 0:
                torch.cuda.empty_cache()
                
        return adv_images



    def attack(self, val_loader, device, enable_eval=True, show_progress=True):
        """æœ€æ ¸å¿ƒçš„å‡½æ•°ï¼šå…¨GPUåŒ–æ”»å‡»æµç¨‹ (æ–°å¢å…¨å±€å‡†ç¡®ç‡è®°å½•åŠŸèƒ½)"""
        progress_bar = tqdm(range(max_iter), desc="ğŸ”¥GPUæ”»å‡»è¿›ç¨‹") if show_progress else range(max_iter)
        
        for t in progress_bar:
            # 1. ç”Ÿæˆæ‰°åŠ¨å¹¶æ›´æ–°é€šç”¨æ‰°åŠ¨
            delta, blocks = self.sample_perturbations()
            delta = delta.unsqueeze(0).to(self.device)  # ç¡®ä¿ delta åœ¨ GPU ä¸Š

            # 2.æ›´æ–°å…¨å±€æ‰°åŠ¨
            self.universal_perturbation = torch.clamp(
                self.universal_perturbation + delta,   # torch.clamp:å¯¹å¼ é‡è¿›è¡Œå…ƒç´ çº§çš„èŒƒå›´é™åˆ¶ï¼Œæ¯ä¸ªå…ƒç´ éƒ½ä¸èƒ½å°äºç¬¬äºŒä¸ªå‚æ•°ï¼Œä¹Ÿä¸èƒ½å¤§äºç¬¬ä¸‰ä¸ªå‚æ•°
                -self.epsilon,  # æ‰°åŠ¨å¹…åº¦çº¦æŸ
                self.epsilon
            )
            if debug_mode:
                # === æ–°å¢å¯è§†åŒ–è°ƒç”¨ç‚¹1ï¼šæ‰°åŠ¨ç”Ÿæˆå ===
                self.visualizer.plot_perturbation(
                    cid=self.label.item(),
                    delta=delta.detach().cpu(),
                    universal_pert=self.universal_perturbation.detach().cpu(),
                    iteration=t
                )
            # print(f"\nIteration {t}, Epsilon: {self.epsilon}, Perturbation Norm: {torch.norm(self.universal_perturbation).item()}")

            # 3. ç”Ÿæˆå¯¹æŠ—æ ·æœ¬
            adv_images = self.original_image.to(self.device) + self.universal_perturbation # è¿™é‡Œçš„adv_imagesæ˜¯ä¸€ä¸ªå››ç»´å¼ é‡

                # ==== æ–°å¢è°ƒè¯•ä»£ç  ====
            if epsilon == 0:
                # æ•°å€¼ä¸€è‡´æ€§æ£€æŸ¥
                if not torch.allclose(self.original_image, adv_images, atol=1e-6):
                    print("âš ï¸ é›¶æ‰°åŠ¨ä¸‹æ•°æ®ä¸ä¸€è‡´ï¼æœ€å¤§å·®å¼‚:", 
                        torch.max(torch.abs(self.original_image - adv_images)).item())
                
                # æ•°æ®èŒƒå›´æ£€æŸ¥
                print("åŸå§‹æ•°æ®èŒƒå›´: [{:.3f}, {:.3f}]".format(
                    self.original_image.min(), self.original_image.max()))
                print("æ‰°åŠ¨åèŒƒå›´: [{:.3f}, {:.3f}]".format(
                    adv_images.min(), adv_images.max()))
                
                
                # ==== è°ƒè¯•ç»“æŸ ====
            # ==== æ–°å¢ï¼šæ¯æ¬¡è¿­ä»£éƒ½ç”ŸæˆæŠ¥å‘Š ====
            with torch.no_grad():
                outputs = self.model(adv_images)
                adv_pred = outputs.argmax().item()
                
            # ä¿å­˜å½“å‰è¿­ä»£çš„æŠ¥å‘Šï¼ˆåŒ…å«è¿­ä»£æ¬¡æ•°ï¼‰
            self.save_attack_report(
                orig_img=self.original_image,
                adv_img=adv_images.squeeze(),
                true_label=self.label.item(),   #  1. éç›®æ ‡æ”»å‡»æ—¶ï¼Œè®°å½•è¢«æ”»å‡»çš„åŸå§‹ç±»åˆ« 2. ç›®æ ‡æ”»å‡»æ—¶ï¼Œéœ€æ”¹ä¸ºç›®æ ‡ç±»åˆ«.æ³¨ï¼šå½“ label æ˜¯å•ä¸ªæ•°å€¼å¼ é‡æ—¶ï¼ˆå¦‚åˆ†ç±»æ”»å‡»çš„ç›®æ ‡ç±»åˆ«ï¼‰ï¼Œè¿™æ˜¯æ­£ç¡®çš„æ–¹æ³•ã€‚åœ¨æ‰¹é‡æ”»å‡»æ—¶ä¼šå‡ºé”™ï¼
                adv_label=adv_pred,
                original_path=self.original_path,
                iteration=t  # æ–°å¢è¿­ä»£å‚æ•°
            )

            # 4. è°ƒç”¨ evaluate å‡½æ•°è®¡ç®—æŸå¤±å€¼ && æ›´æ–°å—é€‰æ‹©æ¦‚ç‡
            losses = self.evaluate(adv_images)
            self.update_prob(blocks, losses)
            
            if debug_mode:
                # === æ–°å¢å¯è§†åŒ–è°ƒç”¨ç‚¹2,3ï¼šæ¦‚ç‡æ›´æ–°å ===
                self.visualizer.log_block_heatmap(
                    cid=self.label.item(), #  1. éç›®æ ‡æ”»å‡»æ—¶ï¼Œè®°å½•è¢«æ”»å‡»çš„åŸå§‹ç±»åˆ« 2. ç›®æ ‡æ”»å‡»æ—¶ï¼Œéœ€æ”¹ä¸ºç›®æ ‡ç±»åˆ«.æ³¨ï¼šå½“ label æ˜¯å•ä¸ªæ•°å€¼å¼ é‡æ—¶ï¼ˆå¦‚åˆ†ç±»æ”»å‡»çš„ç›®æ ‡ç±»åˆ«ï¼‰ï¼Œè¿™æ˜¯æ­£ç¡®çš„æ–¹æ³•ã€‚åœ¨æ‰¹é‡æ”»å‡»æ—¶ä¼šå‡ºé”™ï¼
                    iteration=t,
                    selected_blocks=blocks.cpu().numpy()
                )
                self.visualizer.log_block_distribution(
                    class_id=self.label.item(), #  1. éç›®æ ‡æ”»å‡»æ—¶ï¼Œè®°å½•è¢«æ”»å‡»çš„åŸå§‹ç±»åˆ« 2. ç›®æ ‡æ”»å‡»æ—¶ï¼Œéœ€æ”¹ä¸ºç›®æ ‡ç±»åˆ«.æ³¨ï¼šå½“ label æ˜¯å•ä¸ªæ•°å€¼å¼ é‡æ—¶ï¼ˆå¦‚åˆ†ç±»æ”»å‡»çš„ç›®æ ‡ç±»åˆ«ï¼‰ï¼Œè¿™æ˜¯æ­£ç¡®çš„æ–¹æ³•ã€‚åœ¨æ‰¹é‡æ”»å‡»æ—¶ä¼šå‡ºé”™ï¼
                    iteration=t,
                    prob_dist=self.prob.cpu()
                )
            
                # === æ–°å¢å¯è§†åŒ–è°ƒç”¨ç‚¹4ï¼šCMA-ESæ›´æ–° ===
                for bid in blocks.unique().cpu().numpy():
                    self.visualizer.visualize_cma_es(
                        cid=self.label.item(), #  1. éç›®æ ‡æ”»å‡»æ—¶ï¼Œè®°å½•è¢«æ”»å‡»çš„åŸå§‹ç±»åˆ« 2. ç›®æ ‡æ”»å‡»æ—¶ï¼Œéœ€æ”¹ä¸ºç›®æ ‡ç±»åˆ«.æ³¨ï¼šå½“ label æ˜¯å•ä¸ªæ•°å€¼å¼ é‡æ—¶ï¼ˆå¦‚åˆ†ç±»æ”»å‡»çš„ç›®æ ‡ç±»åˆ«ï¼‰ï¼Œè¿™æ˜¯æ­£ç¡®çš„æ–¹æ³•ã€‚åœ¨æ‰¹é‡æ”»å‡»æ—¶ä¼šå‡ºé”™ï¼
                        bid = bid,
                        cma_state={
                            'mean': self.cma_blocks[bid].mean,
                            'C': self.cma_blocks[bid].C,
                            'sigma': self.cma_blocks[bid].sigma,  # æ–°å¢å½“å‰sigma
                            'sigma_history': self.cma_blocks[bid].sigma_history
                        },
                        iteration=t
                    )
            # 5. è®¡ç®—å½“å‰æœ€ä½³æŸå¤±å€¼
            with torch.no_grad():
                outputs = self.model(adv_images)
                loss = nn.CrossEntropyLoss()(outputs, self.label.view(-1))
                loss += lambda_sparsity * torch.norm(delta, p=1)
            
            # 6. æ›´æ–°æœ€ä½³ç»“æœ
            if loss > self.best_loss:
                self.best_loss = loss
                self.best_adv = adv_images

            
            # 7. è®°å½•å…¨å±€å‡†ç¡®ç‡
            if enable_eval and (t % self.eval_interval == 0):
                attacked_val_images = []
                attacked_val_labels = []
                for images, labels in val_loader:
                    images = images.to(self.device)
                    labels = labels.to(self.device)
                    adv_images = self.attack_batch(images, labels)
                    attacked_val_images.append(adv_images)
                    attacked_val_labels.append(labels)
                    # ------------------è°ƒè¯•begin: é€ä¸ªå›¾åƒå¤„ç†(è°ƒè¯•ç»“æœ:ä¸ºæ”»å‡»æƒ…å†µä¸‹å‡†ç¡®ç‡è¿‡ä½çš„åŸå› ä¸åœ¨è¿™)----------------
                    # for i in range(images.shape[0]):
                    #     perturbed_img = torch.clamp(images[i] + self.universal_perturbation, 0, 1)  # æ·»åŠ å…¨å±€æ‰°åŠ¨
                    #     attacked_val_images.append(perturbed_img)  # æ·»åŠ æ‰°åŠ¨åçš„å›¾åƒï¼Œå¹¶ä¿æŒæ‰¹æ¬¡ç»´åº¦
                    #     attacked_val_labels.append(labels[i].unsqueeze(0))  # æ·»åŠ æ ‡ç­¾ï¼Œå¹¶ä¿æŒæ‰¹æ¬¡ç»´åº¦
                    # ------------------è°ƒè¯•end: é€ä¸ªå›¾åƒå¤„ç†----------------

                attacked_val_images = torch.cat(attacked_val_images, dim=0)
                attacked_val_labels = torch.cat(attacked_val_labels, dim=0)

                attacked_dataset = TensorDataset(attacked_val_images, attacked_val_labels)
                attacked_dataloader = DataLoader(attacked_dataset, batch_size=64, shuffle=False)
                current_acc = evaluate_global_accuracy(self.model, attacked_dataloader, device)
                self.global_acc_history.append(current_acc)
                
                if current_acc > 0 and self.early_stopping(current_acc):
                    print(f"Early stopping at iteration {t} due to no improvement in global accuracy.")
                    break

            global_acc = np.mean(self.global_acc_history)

            # 8. æ›´æ–°è¿›åº¦æ¡
            if enable_eval:
                progress_bar.set_postfix(
                    Global_Acc=f"{global_acc:.2f}%" if enable_eval else "N/A", 
                    Current_Acc=f"{current_acc:.2f}%", 
                    Loss=f"{loss.item():.4f}"
                )
        
        # ç¡®ä¿ global_acc_history é•¿åº¦è¶³å¤Ÿ
        if len(self.global_acc_history) < max_iter:
            self.global_acc_history.extend([self.global_acc_history[-1]] * (max_iter - len(self.global_acc_history)))
        
        return self.best_adv.squeeze(0)

    def save_attack_report(self, orig_img, adv_img, true_label, adv_label, original_path, iteration):
        """ä¿å­˜æ”»å‡»æ•ˆæœæŠ¥å‘Šå›¾ï¼ˆæŒ‰ç±»åˆ«ç»„ç»‡ç›®å½•ç»“æ„ï¼‰"""
        # è§£æåŸå§‹è·¯å¾„è·å–æ•°æ®é›†ç±»å‹å’Œç±»åˆ«ä¿¡æ¯
        path_parts = original_path.split(os.sep)
        
        # å®šä½å…³é”®è·¯å¾„èŠ‚ç‚¹ï¼ˆå‡è®¾è·¯å¾„ç»“æ„ä¸º: .../tiny-imagenet-200/[trainæˆ–val]/class_folder/images/xxx.JPEGï¼‰
        try:
            dataset_type = path_parts[path_parts.index('tiny-imagenet-200') + 1]  # è·å–trainæˆ–val
            class_folder = path_parts[path_parts.index(dataset_type) + 1]        # è·å–ç±»åˆ«æ–‡ä»¶å¤¹åç§°
        except ValueError:
            dataset_type = "unknown_dataset"
            class_folder = "unknown_class"

        # æ„å»ºä¿å­˜è·¯å¾„ï¼ˆæ ¼å¼: attacked_images/[train|val]/[class_folder]/ï¼‰
        base_path = os.path.join("attacked_images", dataset_type, class_folder)
        os.makedirs(base_path, exist_ok=True)

        # ç”Ÿæˆå¸¦è¿­ä»£æ¬¡æ•°çš„æ–‡ä»¶å
        filename = os.path.basename(original_path).split('.')[0]
        save_path = os.path.join(base_path, f"{filename}_iter{iteration}_report.png")

        # ä»¥ä¸‹ç»˜å›¾ä»£ç ä¿æŒä¸å˜...
        orig_img_np = orig_img.cpu().numpy().transpose(1, 2, 0)
        adv_img_np = adv_img.cpu().numpy().transpose(1, 2, 0)
        
        # è®¡ç®—å™ªå£°ï¼ˆåŸºäºå½’ä¸€åŒ–åçš„å¼ é‡ï¼‰
        noise = (adv_img - orig_img).abs().sum(0, keepdim=True)
        noise_norm = noise.squeeze().cpu().numpy()
        noise_norm = (noise_norm - noise_norm.min()) / (noise_norm.max() - noise_norm.min() + 1e-8)

        # ç»˜åˆ¶ä¸‰å›¾åˆä¸€æŠ¥å‘Š
        plt.figure(figsize=(15, 5))
        
        # åŸå§‹å›¾åƒï¼ˆå½’ä¸€åŒ–åï¼‰
        plt.subplot(1, 3, 1)
        plt.imshow(orig_img_np)
        plt.title(f"Original\nLabel: {true_label}")
        plt.axis('off')

        # å¯¹æŠ—æ ·æœ¬ï¼ˆå½’ä¸€åŒ–åï¼Œæœªè£å‰ªï¼‰
        plt.subplot(1, 3, 2)
        plt.imshow(adv_img_np)
        plt.title(f"Adversarial\nPred: {adv_label}")
        plt.axis('off')

        # å™ªå£°çƒ­åŠ›å›¾
        plt.subplot(1, 3, 3)
        heatmap = plt.imshow(noise_norm, cmap='viridis_r', vmin=0, vmax=0.3)
        plt.colorbar(heatmap, fraction=0.046, pad=0.04)
        plt.title("Perturbation Heatmap")
        plt.axis('off')

        plt.tight_layout()
        plt.savefig(save_path, bbox_inches='tight')
        plt.close()
class AttackVisualizer:
    """ä¸SZOAttackå°ºå¯¸å®Œå…¨å…¼å®¹çš„å¯è§†åŒ–ç³»ç»Ÿ"""
    def __init__(self, H, W, block_size, device):
        self.H = H
        self.W = W
        self.block_size = block_size
        self.device = device
        self._init_filesystem()
        
    def _init_filesystem(self):
        """åˆ›å»ºå®Œæ•´çš„æ—¥å¿—ç›®å½•ä½“ç³»,åœ¨ç±»åˆå§‹åŒ–é˜¶æ®µä½¿ç”¨"""
        # å…¨å±€ç›®å½•
        os.makedirs("attack_logs/perturbations", exist_ok=True)
        
        # ç±»ä¸“å±ç›®å½•ï¼ˆæŒ‰æœ€å¤§å¯èƒ½ç±»åˆ«æ•°é¢„åˆ›å»ºï¼‰
        for cid in range(num_test_classes):  # å‡è®¾æœ€å¤š200ä¸ªç±»åˆ«
            class_dirs = [
                f"attack_logs/class_{cid}/block_selections",
                f"attack_logs/class_{cid}/cma_es",
                f"attack_logs/perturbations/class_{cid}"
            ]
            for d in class_dirs:
                os.makedirs(d, exist_ok=True)

    def log_block_heatmap(self, cid, iteration, selected_blocks):
        """çƒ­åŠ›å›¾ä¸“ç”¨æ–¹æ³•ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªç‰ˆæœ¬æ ¸å¿ƒé€»è¾‘ï¼‰,æ­¤æ–¹æ³•åœ¨def attackä¸­è¢«ç›´æ¥è°ƒç”¨"""
        grid_size = self.H // self.block_size
        heatmap = torch.zeros((grid_size, grid_size), device='cpu')

        # è½¬æ¢å—IDåˆ°åæ ‡
        for bid in selected_blocks:
            row = bid // grid_size
            col = bid % grid_size
            heatmap[row, col] += 1

        # ç”Ÿæˆå›¾åƒ
        plt.imshow(heatmap.numpy(), cmap='viridis')
        plt.colorbar()
        plt.title(f"Class {cid} Block Heatmap\nIter {iteration}")
        plt.savefig(f"attack_logs/class_{cid}/block_selections/iter_{iteration:04d}.png")
        plt.close()

    def log_block_distribution(self, class_id, iteration, prob_dist):
        """æ¦‚ç‡åˆ†å¸ƒä¸“ç”¨æ–¹æ³•ï¼ˆæ•´åˆç¬¬äºŒä¸ªç‰ˆæœ¬ç‰¹æ€§ï¼‰,æ­¤æ–¹æ³•åœ¨def attackä¸­è¢«ç›´æ¥è°ƒç”¨"""
        plt.figure(figsize=(10, 4))
        plt.bar(range(len(prob_dist)), prob_dist.numpy(), alpha=0.7)
        plt.xlabel('Block ID')
        plt.ylabel('Selection Probability')
        plt.title(f"Class {class_id} Probability Distribution\nIter {iteration}")
        plt.savefig(f"attack_logs/class_{class_id}/block_selections/probs_iter_{iteration:04d}.png")
        plt.close()

    def visualize_cma_es(self, cid, bid, cma_state, iteration):
        """å¯è§†åŒ–CMA-ESæœç´¢è¿‡ç¨‹,æ­¤æ–¹æ³•åœ¨def attackä¸­è¢«ç›´æ¥è°ƒç”¨"""
        # åˆ›å»ºç±»ä¸“å±ç›®å½•
        class_dir = f"attack_logs/class_{cid}"
        cma_es_dir = os.path.join(class_dir, "cma_es")
        os.makedirs(cma_es_dir, exist_ok=True)

        # åˆ›å»ºå¯è§†åŒ–å›¾å½¢
        fig, axs = plt.subplots(1, 2, figsize=(16, 6))
        
        # === å·¦å›¾ï¼šåæ–¹å·®æ¤­åœ† ===
        current_sigma = cma_state['sigma']
        cov = cma_state['C'] * (current_sigma ** 2)  # å½“å‰åæ–¹å·®
        
        # ç‰¹å¾åˆ†è§£ï¼ˆç®€åŒ–ï¼‰
        radius = 2 * current_sigma  # åæ–¹å·®çŸ©é˜µå›ºå®šä¸ºå•ä½é˜µ
        w, v = np.linalg.eigh(cov)
        angle = np.degrees(np.arctan2(v[1,0], v[0,0]))
        ellipse = Ellipse(
            xy=cma_state['mean'],
            width=2*np.sqrt(w[0]),
            height=2*np.sqrt(w[1]),
            angle=angle,
            fc='none', 
            ec='red'
        )
        axs[0].add_patch(ellipse)
        # åŠ¨æ€åæ ‡èŒƒå›´
        max_radius = max(1.5, radius*1.2)
        axs[0].set_xlim(-max_radius, max_radius)
        axs[0].set_ylim(-max_radius, max_radius)
        axs[0].set_title(f"Block {bid} Search Space\nÏƒ={cma_state['sigma']:.3f}")
        
        # å‚æ•°æ¼”åŒ–æ›²çº¿
        axs[1].plot(cma_state['sigma_history'], label='Sigma')
        axs[1].legend()
        axs[1].set_title("Parameter Evolution")
        
        # ä¿å­˜å¹¶å…³é—­
        plt.savefig(os.path.join(cma_es_dir, f"block_{bid}_iter_{iteration:04d}.png"), dpi=150)
        plt.close()
    def plot_perturbation(self, cid, delta, universal_pert, iteration):
        """æ‰°åŠ¨å¯è§†åŒ–å¯¹æ¯”"""
        class_dir = f"attack_logs/perturbations/class_{cid}"
        fig, axs = plt.subplots(1, 3, figsize=(18, 6))
        
        # å½“å‰è¿­ä»£æ‰°åŠ¨
        axs[0].imshow(delta.squeeze().permute(1,2,0).numpy() * 3 + 0.5)
        axs[0].set_title(f"Class {cid} Iter {iteration} Delta")
        
        # ç´¯ç§¯æ‰°åŠ¨
        axs[1].imshow(universal_pert.squeeze().permute(1,2,0).numpy() * 3 + 0.5)
        axs[1].set_title(f"Class {cid} Accumulated Pert")
        
        # æ‰°åŠ¨å¹…åº¦çƒ­åŠ›å›¾
        heatmap = torch.norm(universal_pert.squeeze(), dim=0)
        axs[2].imshow(heatmap, cmap='inferno')
        axs[2].set_title(f"Class {cid} Pert Magnitude")
        
        plt.savefig(os.path.join(class_dir, f"iter_{iteration:04d}.png"))
        plt.close()


# è¿™ä¸ªå‡½æ•°è¢«æš‚æ—¶å¼ƒç”¨äº†ï¼Œå› ä¸ºå®ƒçš„å‡†ç¡®ç‡è®¡ç®—æ–¹å¼ä¸å¯¹
# åŸå› æ˜¯è¿™é‡Œé¢å¤šè¿›è¡Œäº†ä¸€æ¬¡æ ‡å‡†åŒ–ã€‚æ ‡å‡†åŒ–åªèƒ½è¿›è¡Œä¸€æ¬¡ï¼Œä¸èƒ½å¤šåšï¼ï¼ï¼
# è¿˜æœ‰ä¸€ä¸ªåŸå› ï¼šéš¾é“è®¡ç®—å‡†ç¡®ç‡åº”è¯¥ä½¿ç”¨å…¨å±€å‡½æ•°ï¼Œè€Œä¸è¦è®©modelä¼ å…¥ä¸€ä¸ªç±»å†ä½¿ç”¨ç±»å†…å‡½æ•°è®¡ç®—å—ï¼Ÿè¿™æ˜¯ä¸ºä»€ä¹ˆï¼Ÿ
# ============================å·¥å…·å‡½æ•°===================
def evaluate_global_accuracy(model, val_loader, device):
    """è¯„ä¼°å¸¦/ä¸å¸¦æ‰°åŠ¨çš„å…¨å±€å‡†ç¡®ç‡,å…¶ä¸­ï¼š
    torch.no_grad() : ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œä¸»è¦ç”¨äº æ¨ç†(inference)æˆ– è¯„ä¼°æ¨¡å‹æ—¶ã€‚å®ƒèƒ½å¤Ÿ å‡å°‘å†…å­˜å ç”¨ å’Œ åŠ é€Ÿè®¡ç®—ï¼Œå› ä¸ºåœ¨è¯„ä¼°é˜¶æ®µï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ã€‚
    torch.cuda.amp.autocast() : è‡ªåŠ¨æ··åˆç²¾åº¦ã€‚ä½¿ç”¨fp16åŠ é€Ÿ,é™ä½æ˜¾å­˜å ç”¨"""
    model.eval()
    correct = 0
    total = 0
    # with torch.no_grad(), torch.cuda.amp.autocast(): 
    with torch.no_grad(): #å› ä¸ºlabel 
        for images, labels in val_loader:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            # åœ¨ outputs å¼ é‡çš„ç¬¬ 1 ä¸ªç»´åº¦ï¼ˆå³ç±»åˆ«ç»´åº¦ï¼‰ä¸Šæ‰¾åˆ°æœ€å¤§å€¼ï¼Œå¹¶è¿”å›æœ€å¤§å€¼åŠå…¶å¯¹åº”çš„ç´¢å¼•ã€‚è¿™é‡Œä½¿ç”¨äº† Python çš„å…ƒç»„è§£åŒ…è¯­æ³•ï¼Œ_ è¡¨ç¤ºæˆ‘ä»¬ä¸å…³å¿ƒæœ€å¤§å€¼å…·ä½“æ˜¯å¤šå°‘ï¼Œåªå…³å¿ƒæœ€å¤§å€¼æ‰€åœ¨çš„ç´¢å¼•
            _, predicted = outputs.max(1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)
    return correct / total * 100




# ---------------------------- ä¸»å‡½æ•° ---------------------------
def main():
    # åˆå§‹åŒ–è®¾ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    data_root = "./tiny-imagenet-200"
    # set_seed()
    
    # æ•°æ®åŠ è½½val_loader åœ¨åç»­ä»£ç ä¸­å¤šæ¬¡è¢«ä½¿ç”¨ï¼Œä¾‹å¦‚åœ¨è¯„ä¼°æ¨¡å‹çš„åŸå§‹å‡†ç¡®ç‡å’Œè¿›è¡Œå¯¹æŠ—æ”»å‡»æ—¶ï¼Œéƒ½ä¼šä» val_loader ä¸­è·å–æ•°æ®ã€‚
    # val_loaderä¸­çš„æ•°æ®æ˜¯å·²ç»å½’ä¸€åŒ–çš„
    val_loader = get_tinyimagenet_loader(data_root, train=False) 
    
    # åŠ è½½æ¨¡å‹
    model = DebugVGG16(num_classes=200).to(device) #æ¨¡å‹ç§»åŠ¨åˆ°GPU
    # åœ¨è¿›è¡Œæ¨ç†æ—¶ï¼Œç¡®ä¿è°ƒç”¨ model.eval()ï¼
    model.eval()
    #=================debug : éªŒè¯ç‰¹å¾å›¾å°ºå¯¸(å¼€å§‹)===========
    dummy_input = torch.randn(1, 3, 64, 64).to(device)
    with torch.no_grad():
        output = model(dummy_input)
        print("è¾“å‡ºå¼ é‡å½¢çŠ¶:", output.shape)  # åº”è¾“å‡º [1, 200]
        features = model.features(dummy_input)
        print(f"ç‰¹å¾å›¾å°ºå¯¸: {features.shape}")  # åº”è¾“å‡ºå¦‚ [1, 512, 2, 2]
        flattened = torch.flatten(features, 1)
        print(f"å±•å¹³åç»´åº¦: {flattened.shape}")   # åº”å¦‚ [1, 512*2*2=2048]
    # =================debug : éªŒè¯ç‰¹å¾å›¾å°ºå¯¸(ç»“æŸ)=========== 
    # éªŒè¯åŸå§‹å‡†ç¡®ç‡
    orig_acc = evaluate_global_accuracy(model, val_loader, device) # è¿™é‡Œçš„åŸå§‹å‡†ç¡®ç‡å·²ç»æ­£å¸¸äº†,ä¾§é¢è¯´æ˜è¿™ä¸ªå‡½æ•°æ˜¯æ²¡æœ‰é—®é¢˜çš„ã€‚å¦‚æœä¸æ­£å¸¸å¯èƒ½æ˜¯å½’ä¸€åŒ–æ¬¡æ•°è¶…è¿‡ä¸€æ¬¡æˆ–è€…åšäº†ä¸å¿…è¦çš„æ•°æ®å¢å¼ºå¯¼è‡´
    
    print(f"\nåŸå§‹æ¨¡å‹å‡†ç¡®ç‡: {orig_acc:.2f}%")
    
    # æŒ‰ç±»åˆ«æŠ½æ ·æµ‹è¯•ï¼ˆä¿®æ”¹æ ‡ç­¾å¤„ç†éƒ¨åˆ†ï¼‰
    # æŠ½æ ·å¾—åˆ°çš„æ ·æœ¬å°†å­˜å‚¨åœ¨ class_samples å­—å…¸ä¸­ï¼Œimg æ˜¯è¯¥ç±»åˆ«çš„å›¾åƒå¼ é‡ï¼Œlbl æ˜¯å¯¹åº”çš„æ ‡ç­¾å¼ é‡ã€‚
    # class_sampleså­˜æ”¾çš„æ˜¯åŸå§‹çš„å›¾åƒå¼ é‡å’Œæ ‡ç­¾
    class_samples = {}
    dataset = val_loader.dataset
    for idx in range(len(dataset)):
        img, lbl = dataset[idx]
        lbl_value = lbl
        if lbl_value not in class_samples:
            # å­˜å‚¨å›¾åƒè·¯å¾„ä¿¡æ¯
            img_pth = dataset.imgs[idx][0]
            label_tensor = torch.tensor(lbl, dtype=torch.long)  # è½¬æ¢ä¸ºå¼ é‡
            class_samples[lbl_value] = (img, label_tensor, img_pth)
        if len(class_samples) >= num_test_classes:
            break
    
    # æ‰§è¡Œæ”»å‡»
    attack_success = 0
    total_l0, total_l1 = 0, 0.0
    # åœ¨mainå‡½æ•°ä¸­å®šä¹‰å…¨å±€æ‰°åŠ¨,æ³¨æ„è¿™ä¸ªæ‰°åŠ¨æ˜¯è·¨ç±»åˆ«çš„,è¿™æ ·åœ¨ä¸åŒç±»åˆ«ä¸Šçš„æ‰°åŠ¨æ•ˆæœæ‰èƒ½ç›¸äº’å½±å“
    universal_perturbation = torch.zeros((1,3,64,64), device=device)  # åˆå§‹åŒ–ä¸ºå››ç»´
    # è¿™ä¸ªæ•°æ®ç»“æ„:å­˜å‚¨æ‰€æœ‰ç±»åˆ«çš„æ”»å‡»å†å²
    all_class_history = {
        # æ ¼å¼ï¼š{class_id: {'global_acc': [], 'iterations': []}, ...}
    }

    test_progress = tqdm(class_samples.items(), desc="æ”»å‡»è¿›åº¦")
    
    for class_id, (image, label,img_path) in test_progress:  # æ­¤å¤„labelå·²ç»æ˜¯å¼ é‡
        # è¿™ä¸¤è¡Œæ˜¯å½“å‰ç‰ˆæœ¬æ–°åŠ çš„:å°†å½“å‰å›¾åƒå’Œæ ‡ç­¾ç§»åŠ¨åˆ°GPU
        image = image.to(device)
        label = label.to(device)
        attacker = SZOAttack(
            model=model,
            image=image, # åŸå§‹å›¾åƒ
            label=label, # åŸå§‹æ ‡ç­¾(è¿™é‡Œæ˜¯å¼ é‡)
            block_size=block_size,
            original_path=img_path,
            device=device,
            epsilon=epsilon,  # ä¼ é€’å…¨å±€å‚æ•°,ä¸ç„¶ä¼šä½¿ç”¨é»˜è®¤å€¼0.1
            universal_perturbation=universal_perturbation  # ä¼ å…¥å…±äº«æ‰°åŠ¨
        )
        print("Visualizer exists:", hasattr(attacker, 'visualizer'))  # åº”è¾“å‡ºTrue
        # print("Logger exists:", hasattr(attacker, 'logger'))          # åº”è¾“å‡ºTrue
        adv_img = attacker.attack(val_loader, device)
        # è®°å½•å½“å‰ç±»åˆ«çš„æ”»å‡»å†å²
        all_class_history[class_id] = {
            'global_acc': attacker.global_acc_history,
            'iterations': list(range(0, max_iter, attacker.eval_interval))
        }

        for class_id, data in all_class_history.items():
            plt.figure(figsize=(10, 5))
            plt.plot(
                data['iterations'], 
                data['global_acc'], 
                marker='o', 
                label=f'Class {class_id} Attack'
            )
            plt.axhline(y=orig_acc, color='r', linestyle='--', label='Original Accuracy')
            plt.title(f"Global Accuracy During Class {class_id} Attack")
            plt.xlabel("Attack Iteration")
            plt.ylabel("Accuracy (%)")
            plt.legend()
            plt.grid(True)
            plt.savefig(f"global_acc_class_{class_id}.png")
            plt.close()  # é¿å…å†…å­˜æ³„æ¼


        universal_perturbation = attacker.universal_perturbation  # æ›´æ–°å…¨å±€æ‰°åŠ¨
        
        # è¯„ä¼°æ”»å‡»æ•ˆæœï¼ˆä¿®æ”¹æ¯”è¾ƒé€»è¾‘ï¼‰
        with torch.no_grad():
            logits = model(adv_img.unsqueeze(0))
            pred = logits.argmax().item()
            attack_success += int(pred != label.item())  # ç”¨.item()è·å–æ•´å‹å€¼æ¯”è¾ƒ
        
        # è®¡ç®—æ‰°åŠ¨æŒ‡æ ‡
        delta = (adv_img - image).abs().sum(0)
        total_l0 += (delta > 0.005).sum().item()
        total_l1 += delta.sum().item()
        
        # æ›´æ–°è¿›åº¦
        current_sr = attack_success / (list(class_samples.keys()).index(class_id) + 1) * 100
        test_progress.set_postfix(Success=f"{current_sr:.1f}%")
    
    # æ‰“å°ç»“æœ
    print(f"\næœ€ç»ˆæ”»å‡»æˆåŠŸç‡: {attack_success/len(class_samples)*100:.1f}%")
    print(f"å¹³å‡L0æ‰°åŠ¨: {total_l0/len(class_samples):.1f}, å¹³å‡L1æ‰°åŠ¨: {total_l1/len(class_samples):.1f}")
    
    # åªåŠ è½½ä¸€ä¸ªç±»çš„ç»˜å›¾é€»è¾‘(æš‚æ—¶æ³¨é‡Šæ‰)
    # if attacker.global_acc_history:
    #     plt.figure(figsize=(10, 5))
    #     x_axis = np.arange(0, len(attacker.global_acc_history)*attacker.eval_interval, attacker.eval_interval)
    #     plt.plot(x_axis, attacker.global_acc_history, marker='o', color='red', label='Global Acc (Perturbed)')
        
    #     # ç»˜åˆ¶åŸå§‹å‡†ç¡®ç‡ä½œä¸ºå¯¹æ¯”åŸºçº¿
    #     plt.axhline(y=orig_acc, color='blue', linestyle='--', label='Original Accuracy')
        
    #     plt.title("Global Accuracy Under Universal Adversarial Attack")
    #     plt.xlabel("Attack Iteration")
    #     plt.ylabel("Accuracy (%)")
    #     plt.legend()
    #     plt.grid(True)
    #     plt.savefig("global_acc_trend.png")
    plt.figure(figsize=(12, 6))
    colors = plt.cm.viridis(np.linspace(0, 1, len(all_class_history)))

    for (class_id, data), color in zip(all_class_history.items(), colors):


        # å¡«å……æ•°æ®ï¼Œä½¿å¾— global_acc å’Œ iterations çš„é•¿åº¦ç›¸åŒ
        if len(data['global_acc']) < max_iter:
            data['global_acc'].extend([data['global_acc'][-1]] * (max_iter - len(data['global_acc'])))
        if len(data['iterations']) < max_iter:
            data['iterations'].extend([data['iterations'][-1]] * (max_iter - len(data['iterations'])))

        plt.plot(
            data['iterations'], 
            data['global_acc'], 
            marker='o', 
            color=color,
            linewidth=2,
            markersize=8,
            label=f'Class {class_id}'
        )

    plt.axhline(y=orig_acc, color='black', linestyle='--', label='Baseline')
    plt.title("Global Accuracy Under Multi-Class Attacks")
    plt.xlabel("Attack Iteration")
    plt.ylabel("Accuracy (%)")
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')  # å›¾ä¾‹æ”¾åœ¨å³ä¾§
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("all_classes_accuracy_trend.png", bbox_inches='tight')


    with open('attack_history.json', 'w') as f:
        json.dump(all_class_history, f)

if __name__ == "__main__":
    main()

'''
3.26æ™šè¿è¡Œç»“æœ:
arly stopping triggered at score 50.67358547051193 after 10 iterations without improvement.
Early stopping at iteration 22 due to no improvement in global accuracy.
ğŸ”¥GPUæ”»å‡»è¿›ç¨‹:  44%|â–ˆâ–ˆâ–  | 22/50 [03:31<04:29,  9.63s/it, Current_Acc=50.67%, Global_Acc=50.79%, Loss=49.5213]
æ”»å‡»è¿›åº¦: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [1:23:06<00:00, 249.34s/it, Success=30.0%]

æœ€ç»ˆæ”»å‡»æˆåŠŸç‡: 30.0%
å¹³å‡L0æ‰°åŠ¨: 3827.2, å¹³å‡L1æ‰°åŠ¨: 1481.3
'''